#!/usr/bin/env python3
"""æµ‹è¯•API keysé…ç½®å’ŒLLMæä¾›å•†å¯ç”¨æ€§"""

import os
from pathlib import Path
from agent.llm_factory import LLMFactory
from agent.search_utils import SearchUtils

# å°è¯•åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… å·²åŠ è½½ .env æ–‡ä»¶: {env_path}")
    else:
        print(f"âŒ .env æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")
except ImportError:
    print("âš ï¸  python-dotenv æœªå®‰è£…ï¼Œå°è¯•ç›´æ¥è¯»å–ç¯å¢ƒå˜é‡")

def main():
    print("=" * 60)
    print("API Keys å’Œ LLM æä¾›å•†é…ç½®æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥LLM API Keys
    print("\nğŸ”‘ LLMæä¾›å•†API Keysæ£€æŸ¥:")
    llm_keys = [
        ('GEMINI_API_KEY', 'Google Gemini'),
        ('OPENAI_API_KEY', 'OpenAI'), 
        ('DASHSCOPE_API_KEY', 'Qwen/é€šä¹‰åƒé—®'),
        ('XAI_API_KEY', 'Grok')
    ]
    
    for key, name in llm_keys:
        value = os.getenv(key)
        if value:
            masked_value = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else value
            print(f"  âœ… {name}: {key} = {masked_value}")
        else:
            print(f"  âŒ {name}: {key} æœªè®¾ç½®")
    
    # æ£€æŸ¥æœç´¢API Keys
    print("\nğŸ” æœç´¢API Keysæ£€æŸ¥:")
    search_keys = [
        ('GOOGLE_API_KEY', 'Google Search API'),
        ('GOOGLE_CX', 'Google Custom Search Engine ID'),
        ('SERPAPI_API_KEY', 'SerpAPI'),
        ('BING_SEARCH_API_KEY', 'Bing Search API')
    ]
    
    for key, name in search_keys:
        value = os.getenv(key)
        if value:
            masked_value = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else value
            print(f"  âœ… {name}: {key} = {masked_value}")
        else:
            print(f"  âŒ {name}: {key} æœªè®¾ç½®")
    
    # æ£€æŸ¥LLMæä¾›å•†å¯ç”¨æ€§
    print("\nğŸ¤– LLMæä¾›å•†å¯ç”¨æ€§æ£€æŸ¥:")
    providers = ['gemini', 'openai', 'qwen', 'grok']
    
    for provider in providers:
        is_available, error = LLMFactory.check_provider_availability(provider)
        if is_available:
            print(f"  âœ… {provider}: å¯ç”¨")
        else:
            print(f"  âŒ {provider}: {error}")
    
    # æ£€æŸ¥æœç´¢APIå¯ç”¨æ€§
    print("\nğŸ” æœç´¢APIå¯ç”¨æ€§æ£€æŸ¥:")
    available_apis = SearchUtils.get_available_search_apis()
    if available_apis:
        print(f"  âœ… å¯ç”¨çš„æœç´¢APIs: {available_apis}")
    else:
        print(f"  âŒ æ²¡æœ‰é…ç½®ä»»ä½•æœç´¢API")
    
    # æµ‹è¯•å¯ç”¨çš„LLMåˆ›å»º
    print("\nğŸ§ª LLMåˆ›å»ºæµ‹è¯•:")
    for provider in providers:
        is_available, error = LLMFactory.check_provider_availability(provider)
        if is_available:
            try:
                # ä½¿ç”¨é»˜è®¤æ¨¡å‹æµ‹è¯•åˆ›å»º
                from agent.configuration import Configuration
                config = Configuration(llm_provider=provider)
                llm = LLMFactory.create_llm(provider, config.query_generator_model)
                print(f"  âœ… {provider}: æ¨¡å‹åˆ›å»ºæˆåŠŸ ({type(llm).__name__})")
            except Exception as e:
                print(f"  âŒ {provider}: æ¨¡å‹åˆ›å»ºå¤±è´¥ - {str(e)}")
        else:
            print(f"  â­ï¸  {provider}: è·³è¿‡æµ‹è¯• (ä¸å¯ç”¨)")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 60)

if __name__ == "__main__":
    main() 